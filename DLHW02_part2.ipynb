{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ubrRLnG3XJ-W"
   },
   "source": [
    "# Homework 2, *part 2* (60 points)\n",
    "\n",
    "In this assignment you will build a heavy convolutional neural net (CNN) to solve Tiny ImageNet image classification. Try to achieve as high accuracy as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXSnHl87XJ-X"
   },
   "source": [
    "## Deliverables\n",
    "\n",
    "* This file,\n",
    "* a \"checkpoint file\" from `torch.save(model.state_dict(), ...)` that contains model's weights (which a TA should be able to load to verify your accuracy).\n",
    "\n",
    "## Grading\n",
    "\n",
    "* 9 points for reproducible training code and a filled report below.\n",
    "* 12 points for building a network that gets above 20% accuracy.\n",
    "* 6.5 points for beating each of these milestones on the validation set:\n",
    "  * 25.0%\n",
    "  * 30.0%\n",
    "  * 32.5%\n",
    "  * 35.0%\n",
    "  * 37.5%\n",
    "  * 40.0%\n",
    "    \n",
    "## Restrictions\n",
    "\n",
    "* Don't use pretrained networks.\n",
    "\n",
    "## Tips\n",
    "\n",
    "* One change at a time: never test several new things at once.\n",
    "* Google a lot.\n",
    "* Use GPU.\n",
    "* Use regularization: L2, batch normalization, dropout, data augmentation.\n",
    "* Use Tensorboard ([non-Colab](https://github.com/lanpa/tensorboardX) or [Colab](https://medium.com/@tommytao_54597/use-tensorboard-in-google-colab-16b4bb9812a6)) or a similar interactive tool for viewing progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yygq82OGXJ-X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.misc\n",
    "\n",
    "import torchvision\n",
    "# import torch\n",
    "from torchvision import transforms\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "G-9b5JZYXXKW",
    "outputId": "1b45d39b-600a-48e6-8f7c-6a6d0360a268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-19 15:28:40--  https://raw.githubusercontent.com/yandexdataschool/Practical_DL/spring2019/week03_convnets/tiny_img.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3378 (3.3K) [text/plain]\n",
      "Saving to: ‘tiny_img.py’\n",
      "\n",
      "tiny_img.py         100%[===================>]   3.30K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-04-19 15:28:45 (79.9 MB/s) - ‘tiny_img.py’ saved [3378/3378]\n",
      "\n",
      "./tiny-imagenet-200.zip\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/spring2019/week03_convnets/tiny_img.py -O tiny_img.py\n",
    "from tiny_img import download_tinyImg200\n",
    "data_path = '.'\n",
    "download_tinyImg200(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zrgI4mIXJ-i"
   },
   "source": [
    "Training and validation images are now in `tiny-imagenet-200/train` and `tiny-imagenet-200/val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHICKQDeXJ-j"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.RandomCrop(64),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwcBXmlnXJ-k"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/val', transform=transform)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [80000, 20000])\n",
    "test_dataset, val_dataset = torch.utils.data.random_split(val_dataset, [10000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdpcNBiuXJ-m"
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NpSQnqgnXJ-p"
   },
   "outputs": [],
   "source": [
    "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "u4HbFXycXJ-r",
    "outputId": "aa2fd72b-7cd8-4262-9ed6-f87dae1fe2c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n",
      "tensor(179)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztvWmQZNd1Hvid3JeqrL2qq3pvdKMB\nEBQBsLEQJGQQEClQUogOk6ZEMTTQDDyYmNDYtK0ZkxxGKGSFF8oRtsyIsWUjLImwLYmkFgoQKYoE\nIdAiCAhEA2gA3WgAvRV6q70qqyr3l5nXPyo7z9KV1dno7qzm5P0iOvq+uvfdd9997+Y7555zvkPO\nOXh4eHQXQps9AA8Pj87DL3wPjy6EX/geHl0Iv/A9PLoQfuF7eHQh/ML38OhC+IXv4dGFuKKFT0QP\nEdFbRHSciD5/tQbl4eFxbUHv1oGHiMIA3gbwEQBnAbwI4NPOuTeu3vA8PDyuBSJXcO5dAI47504C\nABF9FcDHAbRc+DGKuwTSV3BJj4tApI/lD7mq2qDdRX3K7oVQGDJ9hMLcXcQIj7bthXZ2vBsMEfJW\nNhwvn+jMMOqRVuNofe2L6lq0A4BQVZZ5jFQ145XjN3PjwnL8re8lvJDfYGBrKCGPiitvdAcArmzh\nbwVwRhyfBXD3RickkMbd9OAVXNLDguJxdewCfhNJvmDhsG5XLrfuM8KvBcViXE4ldbse/hGvDfWq\nulqKz5MKZT2s32b1cpsFQTVeLKFKveV4nVjcQY9+pUsDfN91MQXOvPm1KPdRj5oLUIsygMQCjzGx\nWOPyfEl3UeXx15L6AkGGB1NN8oQEST1X/f/teVwKL7inL9kGuLKF3xaI6FEAjwJAAqlrfTkPD482\ncCUL/xyA7eJ4W+NvCs65xwA8BgAZGvz/TURQZOtEs+yqVV1ZF7fpzJfKtpWn5ViUU1/aSOvHVDdf\n7lCMvyauxtd2lYpul+IfYSklAICrBnwgJQgjbruI+ISa2wyV+bxamsdUS+ivWF18aUOB7l+2rKZ5\nDqz4Lr/e5V4t2cRX+CtcjYuvaUr3EQoJMb21cHERqglxIFWkoKbaLb0n0yzXzeN0YsiVDHei+gbQ\n3/6wLokr2dV/EcA+ItpNRDEAvwjgyaszLA8Pj2uJd/3Fd85Viej/AvAdAGEAv+ecO3LVRubh4XHN\ncEU6vnPuLwH85VUai4eHR4dwzTf3rjYie3bxgTXx1IVyVt/AnFLT+ldLhNrThKwOrnR+eylpHjP6\nv9yhl33US1qPpxamMgCA2pFn3TqU1Aoj9fbwtfLaTFRvZTWypjhxbPV/qvCNS32ferUVoh5nBVfu\n4ts+pTUgXDbtpOnMPPZojscRLvJ8R0r62daE/m/NeXKXX+7+r12ci8WhsChnVLOF24SFoqT7iOb4\nuJZsfS9XE95l18OjC+EXvodHF6Kzon4qAbrlPetWKTGvbuwp8rCgHSPaxmZxC5L1aJP32fp3l4zD\njcIGqoo04YX7+/jvfdrBBhU22VFdO+aEWqkjZkwkroWgPfUpXAzUcUioBGS1M2kes56BchzCOSZS\nNGMUKp/0sqsZib0m/I2qSV1Z7ufjSr8eZGVQ3HdczH1Cm0h7XmTzaaSg+5CqS7mPrxUtXLt31n/x\nPTy6EH7he3h0IfzC9/DoQnRUxyd3scmmCWWKM+cFrd1cdR/SFHKNdfoNosxog2ixNV+nCzB6sdDd\nKcFmL4qaiMaA3W+lmy8AhKRe3yPcchM6MISkiTChTWzy2huaSOVeQ0Xr7ipiLincj8v6nkN1cZ41\nCZZFnRiHi+l7cSlhBjWmzvlb2YxZET6vpVE9DhcXxzUbLCTuJWpezohw9Y2IQJxi66Ul9wwAoCa2\nWEpj/K5HlvV+xVDLHi8f/ovv4dGF8Avfw6ML0XnPvYbIdpHIrzzr6q3rWpWvJ0jvORONp+PPzfRH\nhQi7gYefhIyyAwCMDq7bjooV8wcpvtpxiGM5x0acl+Y8qhq1RXr1LbcmkHApFsXrPca7MM7zIcX+\n6qBWffITLOoXh/S3rPDBXLNcqwovQTuOiqgzXn1UF/dS1eJ3Pcn37cTDpZh+ZrntwuSYb+39J829\nIaPhnv6Ne5vlHb/xHK4E/ovv4dGF8Avfw6ML0VlR3znlZWXrWmIjnrZOQo6j3TGZAB6SO+F2FzvD\n3nUycKa+WlDtQiKYhwY1PUO9VeCMGa8S7y0dVqv7NLv/avzW8iLHIVQEl4ipZvU097m6S6stua2C\nNksMN2QMCMUxMY7deq76e4vN8twUWzysKB5LsyoUFLUnIwbYAhI6r9WRegtSqXjSqEVLfF7IaF3y\n3mLzQk00S6UWv3qqrf/ie3h0IfzC9/DoQviF7+HRhei8Oa+VLm+9wq4H2ChBGZ22gf6saaJbk1dc\nBNEn9TBRRjih9UoZgQdjRpP6tDSxuaTWz2tp1mPDea10UguTqTPEJIpLP6y96WY+ONAsS0JN68mY\n38b3EtpaVHXxBN9LuSzINmsmclGE9ZFh0ciXeE9hbCLbLK8U9JwW51lZDw9o4pPeZ7mu/4Seq0of\nj2v+E7y/UFrW8x2P8hgD44hZj3GdNPXZubocEtBLwX/xPTy6EH7he3h0ITbBc+/KRHpphrooeEea\npaz3n0SbXHrXBFINsHMhvekkD74h0aj3CjHV3GZlhEX45LG5lsOITC3xtVZXdeXWLdy9yIgTWtGi\nuAz8yd3Qp+qKD7DHXCLGIvtKVtu/4imuS8aNGF2VHoTCPGgYO0Lhesu6/jSP+fwUqx/pPkPoIoJ0\naiW9LEZf5nsJHzur6nKPD3MXwquvek7fZzUl+AMTJj+BIPBAXlzbaIXR1atn1vZffA+PLoRf+B4e\nXQi/8D08uhCdd9ltl1RDnhZpYUbbCJZ7vpXKfxUi/FzckFzk2KxT2zqs6kKCbNK9Y1IN7t3RLFYz\nrMfLNMoAEF0SurYxD8qssvX5Rf57n+Z5l+cV796nqorD/FoEPTKLrO6jIg4L2/VzHU6un413fCyr\njmuCcLRY0fNYq3Gd1OOjUWPCtCydArLP/kF2gy6Za8lpvOnfLKu6unAzPvov96q6ZEk8azHesOHO\nl6a5yIo1/3Kl5Niva+9mRLQ38hXhkl98Ivo9IpolosPib4NE9BQRHWv8P7BRHx4eHtcX2hH1vwLg\nIfO3zwN42jm3D8DTjWMPD48fE1xS1HfO/Q0R7TJ//jiA+xvlxwF8H8DnLnk1BxatLycaT3rQyTTQ\npp0ig7D9C3HZhVv/3ilVxJJLSC+2/t7W7cS4wjNatHW9bOax3Pl1KfIdPc1/3zWu2gUDJnpMYP69\nIgrsplub5Vrcpm3ie1m413Ddx1hMDwseOUt8Hw7zcSaqRf1afX3TkzLRbdAOAGKiz0hYpOQyp1SF\niF3dIFdBb4Lvq2IINQafZbm6skWbT0/+CpejcW0GLBX4PBfwtU3wH6o9wkMxMOpZIN9N/jtdvlbc\nNt7t5t6Yc26qUZ4GMHaVxuPh4dEBXPGuvnPOYYP0fkT0KBEdJKKDlfpV3J3w8PB413i3u/ozRDTu\nnJsionEAs60aOuceA/AYAPTFtzR/INROPUw6Jht4IvsTovhFPG+ynRHnZSoldS0biCNhxuhEYAvO\nTDWL9X3b9bUEnXRoYUX3KdSA+o07WtYFN3OdzDYLAJFlFlmrfToYZOWAEEXFxFliiKKgjO5Pao+5\nuvCSCwnxPmU86yQCEziTivL14mEefz7QW9Wy/5BRJeRuvey/GOjXVortcmcdAJLCa7Ai+oj9tfY0\nrAlnyMrnl1SdO8vE1qRjezA6zM93/shIs1zXRgM4EYhTSxtq71Xpjcp/lzv8AFAc2XwijicBPNwo\nPwzgiaszHA8Pj06gHXPeHwF4HsB+IjpLRI8A+BKAjxDRMQA/1Tj28PD4MUE7u/qfblH14FUei4eH\nR4fQWc89Erq3NdnJ44u87qQe3tqLT6VWMlzxioRSEl7WbaQUn+eiZh9CpIIOCWLMi0x2KaMIyj6K\nrJ/nbtZ+T5JooZxhYczqi0Fa7AX06LpkD3udVYXuKyPkACAt9PWlvDYPyvMiEb7nqNnzSMe4j2hI\n75XIfYJyjec0HrFmv/a0zZror27Oka+O9errjfN8z3xvG49ph37u1T4+b/nYqL64SJOViOt5XHid\n9XqxlYHKQOv9J8rreYwuS48/0c6o9JVtrfdYLhfeV9/DowvhF76HRxei80E6F1Ih2bRNG0HKctJ7\nzmRNleY3G9gig3Sc8Jij0AYmEpu1d/I897GNySqKO7RpqJrk39PSgP5tlZzwlYweY/aACGwJZFSH\n8ZhLsExZW9Hmse097CshzVeBMXPJHncPLaq6YpXnVYri4VBr02fNcN2NplbXbZcLtPmxLDz5bB9W\nfWiFkGgXMeecOjLRLLvdPPmxOf3+JYY48Mk6fcZjPN+BTaEluPSUShbX4wit8PVsAI/k2ZdmxbCO\nFULUmGSvBP6L7+HRhfAL38OjC+EXvodHF6LzZJsNXBQhp0xFRneXLrbyPGsSlGmbLdmmOE+a6erG\nRKVguqjv39ksV/pYtz53vzEdCp28PmoIKZb53rY+o6uywo2WEsJ0GNZK50CG9fhlY/NJRlgP1C6w\neoxDSe6jbCLmpIttSN6Lax1JZ915e6N83/kqz9V4SrswzxCbRaXZDwCiIUGAKZgsrAmwIrjzA+PO\nm5gXZB4VLg8+MKXaybkKTP8jSSbwqNT1+3J0lqMtI6tcF54x77C8lom6K43K95vHUd2r53SwV5Od\nXgn8F9/DowvhF76HRxeiw557xPx0NvIt3FrkJsk3LznxI+Z3a4N0T7U0i16VfiEapnU7mbLY8pqH\nheQVKbB4VosZ7z/pXFgxXmaiLPsAgN1fF+cRn5fdp012K/exCBwxnmrH3tjaLO/YP9MsDyZ1SHQi\nzCqBNN8BQG+Eb1Sax0qmXUi4GibC7441Yi7Procj6Zyqk9eeWuW8UzHj/TfRz+rD9Iom0SjcyOJx\nvcpzGmR1u90jC81y2IjzCaE+vXZol6qLLQoVRHDn21ReEuVR/cyiWWGGFl6r4QXtUenezyrHmT+5\nVdVt/+RhXA78F9/DowvhF76HRxdi03b1bYorJRjZ1FIyi6wYcWlUR6hIMckZzUF60wWiXDX0dZKb\nzgbHjLzKO9XlAZG9tcdy88myFvliYyxyn/lf9CB3/2duW4tz3dgL2guuOMmDrsd0/z0nuW15lKm9\nV3v0taYeZrew28Y0zXcgRN3BGIuX8aQWsecrPP/W665Y48kbiPE9100K2BsG5pvlW3vPq7onz7yX\n+xfcfNajbyzJ97xa1p6B0e+yV2W5n/sY+fCCapcS6s1kdlDVyT7/zvvfUHV/c5zptqWRKTAqXliQ\n8NG8yaS7yCdGhLYTGEb07ApbEKrGY/Ny4b/4Hh5dCL/wPTy6EH7he3h0ITpuzkPDbOdsdJ6MpqsZ\n85j0tEvyeYVR3YezBB4CoYD7jBZFOiZD/Cuj+oxVB/lx1ltnPiTD/czFRMRWKKb1/5qI7gqHta56\n7h/WRR3vJ/R+VSt7PWeZrUHuBQBAtZf1x0iOzVC1mPFG+xK3m6ruUnWVAa47vJ91ydw92nPs1m2s\nk0vTHgAceuWGZvmGW3kPYX9G87IeL/A+xEJJp/K6cYDTfCeF+fHk6pBqd3SBiTNKz+mUZYU7+Lz0\nED/spYLe3MlX+D6tZ+BNQzzm//HSLaoucZ7nX3rg2TexJqL1MpMmYlM4d8q0We5OHZ7XL0hAltuM\nXGwF/8X38OhC+IXv4dGF2ATPvbVLupgJbBFcd/Wo+T0SclM1IfjgSq3NflbWqgmzV1WY7CR/HaCz\nmlpTmZJmnTiwpAtRIbJHtKgv005ZUT8alvx2XC59RvO8r/6ARd0tzxtdRfL2CzUgXDJc7kKlyW9J\nqbpwicc1cIzFy/6T+pnNJ3bxGA3hyI4pNv2Vn+EUYG8taFF87EvvNMujcW22nC6xilMVD2ZHj56P\nPb083kPTWg2I5lk9S36MVaRsTt+zDDKynoFvClUitmA8PeMyXwP/PZI3ZtxlMXdWShddSqIWmZ4L\nAAoz7L1oyVkuF/6L7+HRhfAL38OjC+EXvodHF6KzOn61itBsQz8zJBrhUOvfINcjUkuLFMZBj9aB\nqinhimuo7VuRXKbmtMJV6RU6spmd/HbRVuhY4bjWnyUXfSTSWo+PGB1fpoJOCD0zHdWEDPmPsq66\nlJ1QdQsH+Lwd3xRurquGz17slSTmyi3r5N4AGVdqGZSYnDF7JSJyspoWpJ89elLPfPnGZnn4/3lF\n1Z1YYn39jlE2CT599CbVbvCH/B5EAkNMusDH05Pc384btFlR5uk7N9+v6nr+B79/cZNuvCq2Cnon\nuVwYM++3eIT5e/S+TLUo5qQs1kFO+4yTIGpxyda8/e2gnRRa24noGSJ6g4iOENFnG38fJKKniOhY\n4/+BS/Xl4eFxfaAdUb8K4Necc7cAuAfArxLRLQA+D+Bp59w+AE83jj08PH4M0E7uvCkAU43yKhEd\nBbAVwMcB3N9o9jiA7wP43CU6gwvWZG6KmegiwZFf70urqvIwe1kFvSLFleXOF4gYejIZmZWeZhG7\nONL6t291nxaPo/0sErtg/TRTgE7jJEV7AIhJNcB4X0mRXp63p2detSvWeO6O/X09B39n6HSzHLqT\nxdcfTN+g2sX/o45AkwhVpVlUmEFTJqWYaBYu6Lly4s2KLfJ9kSGtD3r42X7rtfequp43+T6fGWUx\nvWda33NqVpgOMyY9lTBNRgdYRTozowVUt8TX6tupPeZW7hO5BTZ41stlYZI23n9VcV5tXnsNynmM\njgh+/5N6HdQSwiN0voPReUS0C8DtAF4AMNb4UQCAaQBjVzQSDw+PjqHthU9EPQD+FMA/ds4pqlTn\nnMPFHusXznuUiA4S0cFKvbReEw8Pjw6jrYVPRFGsLfo/cM79WePPM0Q03qgfBzC73rnOuceccwec\ncwdiodZZZD08PDqHS+r4tMZ0+bsAjjrn/p2oehLAwwC+1Pj/iUtejehi3f4CAtbTrO4uzUHVpNA5\nE7qddOEtm7x0vedYxyoIvZ5MJODyB1kqCdu8ekIZC0VkJF1rk13M6IQxUWdTRstjSYZ5fHVEtXtv\nP0fFfXhMu6/enGSz14u5PXzOkOaRf/497Ibad7K1a3JsuTWJpnStDplnFi6IyEBBdGr3CTJvs/AY\nrmgCTCd49Udf5nEUxrSZ6/wv8B7CDWN6P2RqVZh/55gxKNqrTZj1Ie4jO6vHkejnd6K0qD9e6XEe\nfyD2fWrFDfI19JoceKuCCHZJ9N9nTHYyk3zpylxw2rHjfxDALwN4nYgONf72/2JtwX+diB4B8A6A\nT13RSDw8PDqGdnb1n8XF4cUX8ODVHY6Hh0cn0FnPvVCIvfAMEUeth8kfJBEEoCPralFJSKm7D3pY\n/IlntZi+sp1FL+nFt/KB1mmJMj26bkmIgPEMi4qJmBbdElEWS2PGnCfTU0mCx7Vj7kcST9w7cEK1\n+9Y0m71+avRNVXe2wmav96bONMs7ojoVdvpTPP6H+l5Xdb/+L/63Zjma4/kOGa84GeWo7HcwL5Y0\n+5W0WlTawiareFbPoyRWWbxJEIyYgMSRv2Dx+NjHRlXd0CCzV5Z6eL6DYusUV1K0B4BKie9GpjYD\ngFKF+wlEu4sIWHJct/UpLabL/AqnPyXmx6iaJEx40ovv3cD76nt4dCH8wvfw6EJ0nnOvIeKXtmke\nOcmfV4+YHeKyIDuQiUWNW4DcobdBOuEK12U/wGKuFZgSSRYHl+b17m7PkJExG0gbUV9mrJVlQIv3\ncZN2Ki0iOZKiPB/ocfzy1ueb5dW69gKTvPUzVeaU7w/rsd+fYRXhdKDJK37+n3Ia39UaT+SOuOai\nz4m6//zKfapu5HtiXEJizZzS6lM9IjwxTeCWFPWlt6UNngpEcNbgD7T+Fy4K8fhm7i/znqxq15Pg\nd2K1pPsIvcLzH9PJfpG7V3IvigAvs+s++iwPeuYu3Ud1kNWCse+x6tB7RlseFm65MvFewn/xPTy6\nEH7he3h0IfzC9/DoQnRUx3eREIKRNfNNLW5TXHNR6vSA9sirCwIMmQ8PAISj10U6/vI+kUJbpEvu\nHcyrdiuLbF5KGO8uScIYFd56qag1y/FxT1T3Ic108ZDW8TMR3rRIhYTpySQCTAh75JtFTcQxHuPI\nst6QiEYzenyUWhM5yGvPB+ztNmuSuc0JT7ttxoMw//dZV439IUcCVga052a4LLjoq9rU50J835Ve\n4W1pcyvK/sy+jzT/jj/L8z1/s8lt9ztMAtpn8jMsfEZ4F35b77ds/wovoVOfFuMyuQTnPsLvQWhW\nz8GWp4X+/yHuY/ZuM1fiVbW5IbVv56Xhv/geHl0Iv/A9PLoQHRX167EQ8uNrppJqvHVgiBXTS0Pr\nB9UYSVnxmq9o3gm4QRaPZYCNFO2Bi0V/iVyBBzYxyCK1JdRo5YEHAP1RNmf1Grk0JPSdujA0lo39\nqlBnc9P9vUd1neO6ksjzvT2qTXF50YdVA94qMLWCTHd9aGGbahcW933n8Duq7kSOhc/pEIv6uXEj\no5I4dtqbLpbj+ZBemolFLerLdOaxlZqp43mUJuP8gubVL3+Ax2GNZkGWn3vxHv3S5X6aRfhwIEyT\nUaO2CKKPoVf1FaY/zH2GCq2De9x2kTptWc9V+WfvXGvzg+fRDvwX38OjC+EXvodHF8IvfA+PLkRn\ndfwQE2SUhrSeI1ROlEYNyeUA61HVWXYF7T+q+xC8E6haEgOhFkprTapPu5A6YYapVrW+FRdpikOC\nlGNXWke+Ba7172lVkjAadU6a6SRuT02q49Uaz8Hh0nZVVxMa6h1JPu9ERUetvV7g807kdD47GVEY\nExsp+/tn9DgC1n2PLI+rurfP8j5BRuzRGCsXIsXWprn8Fj4vNStddnUn8aWqOMfuEwiz6zy32/f7\n2gRbFu9jqV8/mEAQiThz7T4ROBkS+0/nflKPI9jB73A9YsJKRRReqNTaLbfvGZ7vzGn9rpx5cO16\nlVfac+v1X3wPjy6EX/geHl2Ijor6ieES9j38FgDgvoFjqu75LNvfrAlsb4p5PP/LX/5Us5y91eQb\nFlxmYWNOkTJmaIM0VnXRLhnX4uCWXk7jfHNmulleDLRJ8IbUXLMsveAAbWKzkB56w5HVlu0qot2e\nuOY47Q2x6vJycVezXDCsJT1hFj3vHphUddKrb0Z46y1W9H3+4ugLzfL3lt+j6k6c39EsS1Otcf5D\nqMrzHTZpz2XaKenNGTJanOTxI/PYJclFNMeifi2pX31Zlx/Vor5Msyb7A4DiMPeTWOKBbXtGP/fC\nGJvzpLciAOz8U56D5Ru43H/MpE4TaszqVv0e1dKNPjeg+pPwX3wPjy6EX/geHl2Ijor61XoI2fLa\njvQLy7tVXaXOMkqhqsWYsTjvZt59H3uqPf+CzppKQryvV00QRmR9wgS7p5wW4n2xosdxdpmJLWpi\ndz5sPPekqB83O/V9ghCjZDzVCnUWB5dr7FlW2+D3OajqRzgLlqUlgcdYVDNIjEXZ8zAMkzFYqRx8\n3qmQtgwcLW1tlr97Uj+L9HlBSiHEz6jRYKQGYmnVJcdfTXh6VmK6XXFUqGczRl0QYrVMv2bd82JL\n/NyNponFm4UqUTNqgLieTA8W9Oh2S/v5GY6+oq1Wkiuy/zhfvGLSgeUneNCjr+hBFs+svUtGs2wJ\n/8X38OhC+IXv4dGF8Avfw6ML0VEdPx6uYmfPmpfbyVXtLSY92kaSOVU3LBTD7yze3LL/WkHwmscN\nn32CdSKZ4ipqUlz1xtnMlY5phUma+tKCYGNf75xqJ81hkyV9n8NRvredMZ3uaWtUpJ0S3n81o5D2\nh3if4Fhli6qT17uv961mOUFaJ5RRfAvVHlUn9x7OlTmd9HtS51S7r03f2SyHXtMEFSKTt85xYDZV\nKn20fjsAgQigq/RyO8urX9jG813pN+mpU3yfYy/wfoWL6Hazd/AcpOb0OxGusK7d98C0qjt/gqMQ\nk9/lMUZXdR+BIBI587OGLz/GOn/6dd7PqmkeVQy/LsyRJn1cYmGtT2qd8Uzhkl98IkoQ0Y+I6FUi\nOkJE/7zx991E9AIRHSeirxHRlSXs9vDw6BjaEfXLAB5wzr0PwG0AHiKiewD8FoDfds7tBbAE4JFr\nN0wPD4+riXZy5zkAF+TTaOOfA/AAgF9q/P1xAL8B4Hc26qsQxPDK3BqZw3BKE15sSzPP+YllLR7/\ndY1NRfMzwvUrqc1QJPj4lPkOQF9q/VRZpUBPQSDMNaMpbXuKCZcx6V14V/qkavdOhcd/W/q0qusX\nxGlWxD5TZsKKhJDZdsa0KvGjAns5hozsfEOCPfmOl1kNsLx9kkuvbiJn5L199bUD3Pe2nardibMs\n5vbPm/RaaZl6i/9e7rcBNoJ8xHidFQSdoBzi2EHjulfj71cwqGXdUkFk6u0R3nMl3S6/XY5fDyS6\nKsyK/1WbNOP7+NqJOX62MlswAOz6JpdPfcIsu7IIYhKXTk0Z02SR3+lyv+mjdazTumhrc4+Iwo1M\nubMAngJwAkDWOXdh9s4C2NrqfA8Pj+sLbS1851zNOXcbgG0A7gJw0yVOaYKIHiWig0R0sLqyfiYa\nDw+PzuKyzHnOuSyAZwB8AEA/EV2QN7YBONfinMeccweccwcimdR6TTw8PDqMS+r4RDQCIHDOZYko\nCeAjWNvYewbAJwF8FcDDAJ64VF/hUB2DybWv/l5jApstsznozDtaxz8jUgJHs6wEBVu0uS0iTHbh\nsFZ6emNsfsvEmLTQ6rejCTa3pcOaE1+2lUQch4uahHJvggkrRsLaVXauxnsU31u6RdW9ucjkFSlh\n2rMEGPkqm6jSET3GclykY44x1710BwaAlxeZiGPyNc3N3zvJ3wMZTDd7SJN+9IoploQXAJRLrKxL\nLriW7SzBRqEknrW4WG5C6+B7vsFzcO5+zdQ68pogsgx4HDN36v2V4Ve5Lj+mx7G6l+u2f0ePf9cT\n/HzLw2x/Kw/qaMj0Sd7DigzpMdalG/AEv9OLZ/UYh17j+6z06aV74XVsN7teO3b8cQCPE1EYaxLC\n151z3ySiNwB8lYj+BYBXAPzFrXbMAAAgAElEQVRum9f08PDYZLSzq/8agNvX+ftJrOn7Hh4eP2bo\nbJpsgSNZzdE2OcXc7uFVLcpJadxytkkEBRZne0e0iL1aYdFLesWNJbXJLinCmyyfvfTIe396slme\nFumoAeCvl9i78LV5LUbLiD/pQQgA8SiLpcPCe1Gm1gKA7QkW4Zerxr1L4MUVjoB8YWqHqludYTEy\nVtSTuvJ+vp4r8hwkz+j5kHkNyhm9XSS931TOhJRul5zj+Z69Q4vAQYbF6ugKj7GoLWrIrfBzH3hT\nqxzSg25lN/cvHBIBAD3n+Vrjz+l3om9SiPDGMzC2Kt6rBL+3qbPa+/TUJ6X6qutqeZ7X4hz3FzHP\npTzM45+7XdcNHm6M32hcreB99T08uhB+4Xt4dCE6KuqXg2iTdtkF+jcnOscicDBsmBCkqF8UakDF\nZMsV6YdyaS02Ls2xuBZd5vNO9OhdWpdZn+IaALZPMI32fZm3m+URw4+3LGinc0W9u1vKsVgaT2ur\nxFjv+jx77xQG1XFJpLW6Z+CUqjsrZNg3lthKEBgPxdicCGgKjP6U5TFGC4Ju/FbtbZk4yBx8dcMY\nLXfowxWWP2PLWr1xJMglXtYqTX6cx9FzjusW9+tnWxPEHL3HdR9Loq0MCBo6oseRnOEdc6por770\nOyyap6JaDa3F+Xh1O5eT0+abKqa4Fug+hn7Ez2LhgAggW9bPzAle+GBAj3/uY2vvbfWH7cn6/ovv\n4dGF8Avfw6ML4Re+h0cXorPmvCoBF9IFJ006Y6H2pAd1JF0hJ/NrccNQUetKYZF+qJIz9ADCky91\nK5vD3jt6XjXLCE+4LfFltML3Vzhc4ZcHn1N153L383AXjLlNEILetlV7OUsyktv6zjbLL2e1x9y+\nHo7Asx55EWFyPH9O7A2E9F5GYj/rraGXNYmGNL+lz/KcZkc0OWi/8MKz6QIiggdfkmhGVw0hyATr\n4FHj/VfpESa8YRFZZwglA9EuP6E3G5b3cXnnt1n/j5/Wac+Ke9ncFp3Wz73ez3sZQUbPd0jsX2Te\n4b2B2Tv1nFb6xT7HcfNOCJLOUInfgfHn9VzlJni5UqDnyi03xlVr71vuv/geHl0Iv/A9PLoQHRX1\nqQ5E8mtiGa0YAgwhCuVndaqmiAjMUUEdcWOKk5K/sVBN7GZ+u4+Ov9ksW++8kwUW+WzW2/4oqyDS\ni+/bqz+h2t05wuQb33lZu5l95KOvNsuHl7T34sfGjzTLR3Jc1xfTJqqZMofOfHjgTVX3r498rFn+\n4M3Hm+WXz+tAouI8R0ramMnULuH1eKK/WRx8UcvzkvfeJvqVddUkz+PizfpqcUFyYdWA9Kzk5udy\nZlIHJlUEKUV8SffhXmXRXwbpFG4cUe2SB5lMhTJaTF++kb0cB17UKcuy7+fnK3kB+06ae5nhl3Ne\nvy5w4hWs9/F5q9u0WiFf1VDF5CCYWHs3KeLNeR4eHi3gF76HRxfCL3wPjy5ER3V8R0A9tqbTRVf1\nb04kz8fVtDFVtJn61wmTXdjw6vdE2Qb03Sk2xZ2f1KQf0pyCYa1LZnpZxydBxLGjL6va3ZKZ4nPe\nt6DqIoKw0xJsvLLCZrteYVYcjGlXWZln4C9m36fqZG6Bg9/jKMHwe3S0YqiHdckbHtKEoK8f4/2A\nhLAIDr6p91SKg8JMZ1jVgjTPYzQvCTD0w9z+NM9HqKxdZVPnuC6/jfcGqkndR0iYDosjWi9OT/Fz\nr0d5TPE5M+BRjg6txfVeRnKW56q4R7tP97/GZsGF93Mf0r127ZjL489pe6Qkzuw/yHsSUZOSO57l\n+eib1MOfurcxPyVvzvPw8GgBv/A9PLoQnSfiaEhAZKjRL5j5AMBR698jZWGz9G1V7oNO6wiuyQiL\naEGJbzuc09eSHmgup0W+bEF6TvF5VtR/c5Wj4u4c02L0+SKTdmxJaPG7T5gLt8S5bjyq+5d4aOSw\nOj7xLebcz9/C6oJb1t5id97IUX0vv6NJOnqHWbXIbGNRNr+g03UlllgUtQQp0vuPakIt+o4Wc2cP\nsGi75YXWkXuJRT4v6GnNKR8pavE4khNmtapIo540fcgs6lH9TmzkeVjczqZVmTYsMae9T+e3sYkw\ntqLvU85P71lWdwJDWhJd4WsHvSaV/I/W+pzKt0ew77/4Hh5dCL/wPTy6EJ313HMcSOOstCZERRls\n0zyxAem95Ix8KTngLvJsOsTeV5W9Yqc3aTKXlgWFdl7/LkrCimCExa43Z7R33i1bOKPqawuac69H\n0HxXanoS5I7/Xb0sip8o6f6P59nr7ORXblR1jjeWMfgDlj2Lo3o+Ds3yeX2aywP1CKsFuz7zRrN8\n+qy2gEh1TZJtAHpXW3rMSbEZAMafZ5G4mtC79VIELgvRNraid/9loAzVjOeaCIAJBlj9i5gUV04Q\napx9QNNab/lbfmYyqAgAUufZqzI9w++LpNoGgMw74np1/c5l3mRVLhiWno1anC8P8fMkc5v5LWvj\nr0XbI9j2X3wPjy6EX/geHl0Iv/A9PLoQHdXxY+fy2PXF5wEAZ79wr6qr9EviBq0DRYXJTWa1qpFu\nF1uWoXv62vkdQiEVprjUaatXirI1F4o+A8GvXq+b/QRx4mxW64vbtrM+9/q0js77zL6DzfJzy3ub\n5dt6z6h2X3uG5y6+pbWH2OIdPODEtL7PXpHZe2WvqsL+u1jpf+5tNg9OmBRXiWXWW603HdXXJ+Ko\nZHS7xAKPcf692usumpdmLn4w1pwnrxU25rxQhc+LLfJ+QmmLjgCd/LjM+aVNjsUTrGtn3jbEqjez\nmS59ns8LlbXJribMh7mthsyjKsYihhHN6T6qKUnmqc2FuYmei87fCG1/8Rupsl8hom82jncT0QtE\ndJyIvkZEsUv14eHhcX3gckT9zwI4Ko5/C8BvO+f2AlgC8MjVHJiHh8e1Q1uiPhFtA/CzAP4lgH9K\nRATgAQC/1GjyOIDfAPA77V7YmiNqCSEaRnVlWJrYhJkuUjByjUrVZC4ofuJI9GHFealyWLFJeQam\nhIdVVpt4TqbYptab1iQaxxbZJHb7uObcO7zKpr/+GItyUxWdoit1Xt6MHqM0aQZ9ct50u+x9PK6R\nIS2+Hnt2V7OcFurT0n7dR9+J1vOYnBUm0xiPt2RSUGX38twl5nUnUgUhkVE2NW+CVxa1eU/CRYRK\nluDX/cyD+tW/8UZWp76+/49V3U8/80+a5VramNgygiDkuMjWvKQDq8JxFoj7c/phhEp83vR9IgjI\nPNuwCEYq9WsV8sLzteuqFdr94v97AP8MvLSGAGSdcxdm/CyArW325eHhscm45MInop8DMOuce+nd\nXICIHiWig0R0MED50id4eHhcc7Qj6n8QwM8T0c8ASADIAPgygH4iijS++tsAnFvvZOfcYwAeA4AM\nDbYXQeDh4XFNccmF75z7AoAvAAAR3Q/g/3bOfYaI/hjAJwF8FcDDAJ64nAsXJrQyQkMsDRgOA1Ri\nwiVT8OrH57VpSFpFyqPaFBLNsnAj9xOqWj1XpB8yNfNa/3zeLTuYbCNkFNxTi6yn5U9nVN3IQe7z\n0IR2gR1+nXW94d881Czfln5Htft26UPNsuWzX9nP+m58lm8mtqLHWBIm0+W/1S7BEaEyS52xeJPe\nrxg5xP0HPfpZnPgFfrWiy1wXWdVzGr2TcxxkC5oTf2KI+e1Xb+a66bx+aO48H8eyWoiNi8BGqSNH\nc3oc/2rPn6EV5L7Jyh7tijv6EucnqAzwGOtxvbTOf4jPG3tJ6/iO+LyxH/F+y+ouvVGVEvsmQVr3\nf+aja3NcfWr9e7C4Egeez2Fto+841nT+372Cvjw8PDqIy3Lgcc59H8D3G+WTAO66+kPy8PC41ug8\nEUcDE/s1P3kyKnjNAi2/RkIsb66W2SyyVNP8ZzI1cfKcFj0jwtGpyDwZSowDABEQhqpJoR25ickx\n3jrPnZAR9dM/YJ2jz8hUBXHt9JQ+7/wvsygnqde/+I1fUu2kIccSYKRP8SPVpCVme2WKxeOeM7pO\nppOWnozDT2tRfPYOkULbzNXQQZ5/GYlp02SFTrCp0vBOYOYWFo+rKcnhr286PS2IMoxKk1oQnH4V\nrsvu1+/Hp/78HzXLe3/irKqTXHdL+ww5y35+1unz/A5P/RMtzu/6NSY0cSmtqhQFSUdhK99zbFXP\nVWmQ3/3zn9D91y9EQIbb20bzvvoeHl0Iv/A9PLoQmybqZ+ImLVSOBdiyEfV3DbKYdOYN5n1zCS0K\nJRaE6JnU4mBhgkWgxLzIrrpd7/4rmu8deoyVFRbRxsZ4x3lmUqsccqe9NGICjm5hdWF2WgeKJA/z\n8XdOHmiWh47qPnJbefw2c6zcva9HWkdsjP6Iy8t7jOh8XojVVVE2PIlpYcBd+ik9V8EMi6yRvLSi\n6GvFV/gZ5n5RcxDG/2Zg3WsllmwQFw+sMKpF+MIIH0u1xVpsEpxhDat/q9ONVbZz24mn51VdLcPv\nxMC/ZRWBvrhL9yHSYVXNjrziBSR+eU5/1KirWwUleGAyRV+wfFkXyhbwX3wPjy6EX/geHl0Iv/A9\nPLoQm6bjn8n2q2NpEutJaJ/+hSJ7MEnPLMltD2jPvZLxDk4Jk09smevyO/W47rmfU1X/8PgNqi52\njvW07BkmvIwZVfrVz/1HtMKeP/s/muX+N4w+Os7jigjPssBEGsaFjntRlKMdzIW+NecnIkUR5Xj3\nkqor/pB1a6qvb9oDgKpwYqvl9KskzYxLP8GDHPuhHt/KLp6Dnq/rKMSKMBHGctKcp59tvU2CSTlX\nYwdNXm9pxk3r92r4EEfaFXbqMQ5+YbJZXvg8v0xV48kYLgvvU0O2mb2RJ3LhJ3nTJhLXGzhBWeR1\nmNf0F7WexsOptzcX/ovv4dGF8Avfw6MLsWmifl9Sm38KFTZjFCvanJebZPFq4Fxrc0XQI8R5Y65Z\n3ctyqgxesaQfz53a0yzXC8bsItJ8ScKOWkr3sfub/3uzvPeGaVVH/Sy+Zd+r73NkB4vcoT9iMo+V\nXfr3uf84Xy+7z/x2i+mRwUiZk7pZSLgo5k4a8XVBkKKI7q3psCw8/FLDOvtsfKvwxDzC9yJNkQCQ\nENcKUrpOiuZSvLfqTFjUpWe0K2akwM89sso3IAk6ACC8wu+jNNEBWm0pDWoRfuXXOcNxbJFVAjLR\nX/ntLM7HF7WasfLT4ryKCHwq6PeDxLsa35FTdbXa2v2Q99zz8PBoBb/wPTy6EH7he3h0ITZNx1/K\na0KDoMJDicWNniZ063K/MENpanGVprhmCDaii/wbt/v+yWb57SlNQlFf4Ai0Xd/Suvvybum+yuNI\n3rqo2s1Ns868XNID2THGbWsj+nd3V2ahWX5pO5sLM6f0OKRuHV9QVUjPsk6bH2N9UZqTAKAq9Om+\nY7oPSUYiTXiVHqODC3XSvaz3CRb2s84c2836aPSUJokMi4i5+qf1zcyfYlfoPmH6lOm5Ae1WbPMp\n1ATRZ1jo9ad/Wo+j/xjbTCWBJgDEhRt0elrr5+ESv6syyq440npp1UwOgmCadXkaZFN2/7DR48Vm\nQ25Fr5/I+cZ7W27vW+6/+B4eXQi/8D08uhCbJurHItoNrF5v/RsUErz6MvLNGdLe/G4Wu7bs1GJj\nn4gGPHqK3dhSx7QH1JYXuNOzD+q63kkuh4WakX92RLULjbC8WTmk6+ZuZ5PSB286ruqkp2D4fSzm\nLUe1WJqcEymjytp8EyRD69ZVMq09ukLGiS1a4PMKo9xfdLW1qahHU/MjmkuIMqtPyUUtixeHuf/4\nV3SU4zahBkSKPG+lAf3aJmb5mRW3aNUqt4XF6lqCn+fQEf3+xVaEuXfZqDSiqU3znd/GInf2Br5W\nfq+e1Ggvj7Fe06K+WxWi/jzPVfV1Lc73neCBbJk2L79bM6fOZtsj1vdffA+PLoRf+B4eXYhNE/W3\n9i2r42KVxZ3AiEJTaaaolt5cduc+NsDi/Oy8prUOC0KMLePsIbd0Vu/q1+L8WzjystnV38PjkuKx\nFZXrPSySWQ+xzKssbh5+5RZVN1AS9M9/jzkJt37kvGr30nERWVTWczX0Ih+vimbBDi0a0hKPw2Yn\nJmGxSAhqRJm+DNDZbEvDuq7vFM9BSRAPzn1ae/iN9rFKc2ZS042nJvmdkPyEqzuNuD3O0VmRor6X\n3nOs/kmV4Ng/MF5xeWEBKepn5iKS3AS6LsH3Ge1j/S+T0C9FXlCH1xe1CrnvD/m9dcIK4QzPPAnr\nheVadNHG+C03fQv4L76HRxfCL3wPjy6EX/geHl0IcpZv/RoiQ4Pubnpw3bqVb7MpKxPT+uhQgqOX\njmdZD7Spq3Il1qMK57UJDL2sc+35ff5zLWFMK0JFKg5rhU4ST6wIjo5qxjBUCJ05c8TkuJIwP7ty\nr0CShdh0yVmRrjp1qybRGEyzDp2vsC65+qzeyygPCL11VM93soePpdk1bYghVsV8r57Veyqje9ic\nOjPNpCuxKT0fbg+Pt+8pzTgi57gywdfesiWr2i0ss45frRglPMvXixR4woMB4x2a5fPC1lImXhGr\nW7eC9DYFgNS0IJqZ1tcOF9c3wYVq1g1R6Phm7+gCsepLf/v/YXXl7CVH2dbmHhFNAlgFUANQdc4d\nIKJBAF8DsAvAJIBPOeeWWvXh4eFx/eByRP0PO+duc85d4H3+PICnnXP7ADzdOPbw8PgxwJWY8z4O\n4P5G+XGs5dT73LvtbGdGZE0ta4+lqQKLkU7IWsmYFj1nzjJX3NAr+jet7xSfJwMoSoO6nSR5KGw1\nXnH90oWLi2R4zuJT3H9VU+ejkhEc80Na5KO4SPc0y2J670nDAfeqEAEP6eCYaonnKhhnGTVj0jFF\n3xDHTr8GJGxWVeEJmB/W4wiYXwMJozHmJ1m1iAr+w763dbvSIk9Q9kbdyehLgnAkz2rFojHBxkUG\n3ojO8qUyHNejXN7xF/qZhQLWsyw1vTSjhctGrauvL37XY3quJM9eqKKfxepOtktLL0FJlrLWB5dd\ni0+22yCXgkS7X3wH4LtE9BIRPdr425hz7kKu6GkAY+uf6uHhcb2h3S/+h5xz54hoFMBTRPSmrHTO\nObKZIxto/FA8CgAJpNZr4uHh0WG09cV3zp1r/D8L4BtYS489Q0TjAND4f7bFuY855w445w5EEV+v\niYeHR4dxyS8+EaUBhJxzq43yRwH8JoAnATwM4EuN/5+4koEcOre1WQ7Oa8V4aB+bhnJF/vHIrmgJ\nYvefyGg0S6LBOnNqnhUpyxVfuJdNh5GorgwJXV7uNYQPa9OhNPm4O3Q+uIg8z8hIkoyklubxF8a1\n3ubCIqJt2exDiKmTKcCtTlgcYP3f5hmUHPYyVbMk+QCAzGmh32qrKMp9/IekSDc3/2G9L7Ptz7nd\n+A81AevizXwz489zXblfmwQlEScZvTgUSD57MT4T4SfNuvadkEQfG+nu6rkbXdu630pIklGVJ8HY\nDuVWjCUmDRpbO9VnW15GoR1RfwzAN4joQvs/dM79FRG9CODrRPQIgHcAfKq9S3p4eGw2LrnwnXMn\nAbxvnb8vAFjfG8fDw+O6xqZF51mUl9mkkdmlI/eWX2FvPekRNfa2kcnAx+GSFvkKN/F5JWHOy+/T\noict8jjcgHbhqopIuNCS8Ai7TY+3XGC1gqwnmUC9aqLARFQcpVlOr/boSK/lIb52fF7L2MlZoUqI\nSLWiMcVFZUoqIx5LCbMWFyQo5laCFPeZnNOmyeQCH8/ewePd8ldaTF/aK0xgEW3GTc3x85TivRVz\nXUiQj5j0WpGSlL/F2NOtRfZ62KpWXK4bR8xWqcgvUjnkq2pUvNwOLqu0ZL3m/Rbm3otSZTXeHRfz\nvPoeHh4t4Be+h0cXwi98D48uxHWj4+/971JH1NQ61STXRVdZ360Ys04gUhOvbtO6b6VPmp6EC+aS\nMev0sD2lPqvHQcLlEyOs/xeWtW4aFrqYmzF52ASbi426Uy6ZcT5wMROlJX6urc65ei9Hu7lpvnY9\nZfdDBEz3ct8gOS3054rWH2UUW3avHsiyIBUNrfAFSnP6pvtPru8GDQB5QZQpTYx2HFI/t2nDq4JR\nSZotbR81kWq7qh+nek6O7EPDurDmvEC8BnavRN54bUDs59hQQLknFDKTdeG9ajN60H/xPTy6EH7h\ne3h0Ia4bUX/2dpavtjynSdpLE4JrXJiQAuNxlp/gutKwFoV02mxhNjMSsOFgUKjLEDTpgWfUBQpY\n7K31mwtIST8w6Z5LwrRVFWa0mpHfhKpS7TWyreBldyJ9N5nUSpHC+mYuQJNtVoVTYrCB95mVSsMJ\nVs9Gv8PzM3+bblcWHoTWuzAurKR5kb4rZNJ1S0iVALBeffz35d3GnCdOK05soBa1KUpfDiRhZ2Su\nNXGLIgSJGBPshdux70oL+C++h0cXwi98D48uxHUj6rv7mYhj9sNajFnOsmwXm+TtUZstN77I5+V3\naBE4vrQ+J35xTF8rLrLqFsdapyOiefbOC03ogVTnBLGCEbHVbn3apBEb4PukDTZw68KD0HImUqWF\nqEd2J1yoEibApiZUmrBIXxY287317042y0dPTKi65BEOoFq6SVzXeLRV+mWarNY88iTUDMMbonbJ\nCyajr/XCa/5dU9sra0A0ew2+hxtI4HURdNVzM68DG+keCfMgY2H97kQbxwtJk+ShBfwX38OjC+EX\nvodHF8IvfA+PLsT1o+MLe9D2Ac3SLXWd1Bhzqlf/myZdnP0o68iRc5rtZ+/HTjTLrx7hpHKRFa3g\nlm4WiuySUQSFHhjfwTnfSlOaOMSJ3HmoGLORMLc487tbl6Y+5eFn9POIMNPFzT6BSLkM0Q4VfZ/V\nlPBkNBFdIcE/HxbcGF/+R/9JtXvkyUf5IKH3QyoDfBzJy3xwqhmiwswa0TwcWDrA+mrirMj1Z/Vl\nMT8b8d7Ladx67zlVVxNp2mU+gk5jJS+iQ22gnbw5806EGhtBQdVs2LSA/+J7eHQh/ML38OhCXDei\nvsRcQYvOyRiLfKnf7G2WY//qHdVu9vR4s7z3A7ouE2MR/oE73miWJ3ODqt2po9xHJGdMceKwkudx\nOEOYEFrmaa3HtQgcFmKvTa8tOezrSSHOV438Kg7rxoMLUemtJ3jkDHFDSJjpkmf0fYY0p0YTd8W1\nLC5JUYKY8UIUprmgT4wpaC2LW4+8/kMsco9/YrJZjoX0fFeEPdKmVasL8ViWA2PDLFX5mVkz2mrB\n5GN/F2g3U528trOce+L4orr65V3Hf/E9PLoQfuF7eHQh/ML38OhCXDc6fl3ooOUnTG40wR1/4v/k\n+Lnkt3erdm4PK82FQJtkTpaZsHM0xdF/fTHth3rTrWea5e1pbVacKnKeusOnOA8ArA4+IpT3gp7i\n+jjryfG0VmpDNf4dLucFYWdE7xP09AiOeUPmWZljV9n4HOuxwT7jVrwsIghXdB9O6PhffOSPmuXb\nf/+zup04zdkkAQL1JOvksby+VlhMgXXFLfM2ijK3LVa0qTaoX/n3S+rWYaPj1zaKeGthP7Q6uKrb\nYByhNnX8ixL8XSb8F9/DowvhF76HRxfiuhH1t33iSLO88A8+oOoSiyx7bnmSReDsXt1H7xh70y0W\nDA+eEI0WQ2wutKabXJnFSGvykWrBjTumW7bLFtn8MziuReyBOHPivSrShgFAJcf3lh7g80IhLeqv\nLAhzp/EMDGVYdq4Ps4hdn9bpxpJzMqWzqsKnfuH7zfKvv/zzzXJ1h6EpWWF1IWS4/2tiHCr12KJR\nTUR0npWBa3t4DnJCdatvJAIb2LatUA5aL4WQDY9U126zQozDjkiOPxrjd71uVBjZ5UXUf433mDYY\nq0RbX3wi6ieiPyGiN4noKBF9gIgGiegpIjrW+H/g0j15eHhcD2hX1P8ygL9yzt2EtXRaRwF8HsDT\nzrl9AJ5uHHt4ePwYoJ1suX0AfhLArwCAc64CoEJEHwdwf6PZ4wC+D+BzV2NQg0cK6njpZkHq8B4W\nZeIm1ZZExIjHUpSTakA8or3ApOhfDExW1hb7sVac7E/yrrsU7QFgd5oz/xbGtIz9dp2tGfl5IZpH\n9b1EpTVAOzmiWhZeg8JKkDbeeYHYMU/dvqDqHn/1Hj4QtxyJG5e+ET624nAmzXMwd5qFQZfW9+IE\nZbn1ULxhjMcV1ISFwojA8rhas+JxCyIO8/dK0NpzL5VoTfLnWngGbiRwb6SaJKI8p7V6a5XGjv+C\nNWADWkTdvo02uwHMAfh9InqFiP5LI132mHNuqtFmGmtZdT08PH4M0M7CjwC4A8DvOOduB5CHEevd\nGv/Tuj9yRPQoER0kooPBhhy2Hh4enUI7C/8sgLPOuRcax3+CtR+CGSIaB4DG/7Prneyce8w5d8A5\ndyCK+HpNPDw8OoxL6vjOuWkiOkNE+51zbwF4EMAbjX8PA/hS4/8nrtag5t+nTU/ZWwWpwzCbeHqT\nWoKYnc80y+leHUkm9aNigX+A6glthopFRHpqoy+ultb/4bLkBwkRTTiz0qvqJnbyvsRb57V2JFN2\nUT/3EYrpfYjqLO9RWL3Y9fP40y9xf4UJLZBVx3nu6gV9X60ixKolvecRFuMqGw/FeZEqPDHNdeUh\nw1kvPP5sqrBkhOcgJ8gxakbHl/s3tk56hG6kW1u9XkKSXFpovXv9v190vEEE4eDPvd3yWu3glCtd\nuhHat+P/QwB/QEQxACcB/K9Ykxa+TkSPAHgHwKfexTg9PDw2AW0tfOfcIQAH1ql68OoOx8PDoxO4\nbjz3JFbu0+JKrzANFYRYKkV7AHAlFrnzJuNuTIj0YWHCq1guOpGRtGZE+Fic+5BqRjyqzVy5Io8x\nYsyFf/WtO/laY/o8ybOXfkOkwjISanGcRc9wSVcOf5/F8WpS9HdWt8uK1FWBmQMpikZSPEYrDgfL\nPEbL5x8uinmMi/MyxiRY5GtHM1p1qwgTXk6oWdZUK8X72kXmPFkWabiM+XH7Jw+jm+B99T08uhB+\n4Xt4dCH8wvfw6EJcl/3B92EAAAQzSURBVDq+DWwqFtmUk0qV1/07AISEHl8xpidp1pGRTc6afwR5\nvoyUWhsXn5gv87WjJo+ZNOdls9qnNiquHZs10y+GEojTbI7AnlMysZ6uy4mAP0lsIfPhAUD6JM+P\nMyp+0CvDwLhduKD1+KjMQTiu50ARc2wX5CNR3W7Hr7yOVpAjnsC5lu08Lh/+i+/h0YXwC9/DowtB\nNs3yNb0Y0RzWnH2GAcx37MLr43oYA+DHYeHHoXG549jpnBu5VKOOLvzmRYkOOufWcwjqqjH4cfhx\nbNY4vKjv4dGF8Avfw6MLsVkL/7FNuq7E9TAGwI/Dwo9D45qMY1N0fA8Pj82FF/U9PLoQHV34RPQQ\nEb1FRMeJqGOsvET0e0Q0S0SHxd86Tg9ORNuJ6BkieoOIjhDRZzdjLESUIKIfEdGrjXH888bfdxPR\nC43n87UG/8I1BxGFG3yO39yscRDRJBG9TkSHiOhg42+b8Y50hMq+YwufiMIA/gOAjwG4BcCnieiW\nDl3+KwAeMn/bDHrwKoBfc87dAuAeAL/amINOj6UM4AHn3PsA3AbgISK6B8BvAfht59xeAEsAHrnG\n47iAz2KNsv0CNmscH3bO3SbMZ5vxjnSGyt4515F/AD4A4Dvi+AsAvtDB6+8CcFgcvwVgvFEeB/BW\np8YixvAEgI9s5lgApAC8DOBurDmKRNZ7Xtfw+tsaL/MDAL6JtUQzmzGOSQDD5m8dfS4A+gCcQmPv\n7VqOo5Oi/lYAZ8Tx2cbfNgubSg9ORLsA3A7ghc0YS0O8PoQ1ktSnAJwAkHWumSu3U8/n3wP4Z0Az\nOmpok8bhAHyXiF4iokcbf+v0c+kYlb3f3MPG9ODXAkTUA+BPAfxj59zKZozFOVdzzt2GtS/uXQBu\nutbXtCCinwMw65x7qdPXXgcfcs7dgTVV9FeJ6CdlZYeeyxVR2V8OOrnwzwHYLo63Nf62WWiLHvxq\ng4iiWFv0f+Cc+7PNHAsAOOeyAJ7BmkjdT0QXgnk78Xw+CODniWgSwFexJu5/eRPGAefcucb/swC+\ngbUfw04/lyuisr8cdHLhvwhgX2PHNgbgFwE82cHrWzyJNVpw4CrTg7cCERGA3wVw1Dn37zZrLEQ0\nQkT9jXISa/sMR7H2A/DJTo3DOfcF59w259wurL0Pf+2c+0ynx0FEaSLqvVAG8FEAh9Hh5+KcmwZw\nhoj2N/50gcr+6o/jWm+amE2KnwHwNtb0yS928Lp/BGAKQIC1X9VHsKZLPg3gGIDvARjswDg+hDUx\n7TUAhxr/fqbTYwHwEwBeaYzjMIBfb/x9D4AfATgO4I8BxDv4jO4H8M3NGEfjeq82/h258G5u0jty\nG4CDjWfz5wAGrsU4vOeeh0cXwm/ueXh0IfzC9/DoQviF7+HRhfAL38OjC+EXvodHF8IvfA+PLoRf\n+B4eXQi/8D08uhD/E5k7+61QvoyiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X,y in train_batch_gen:\n",
    "    print(X[0].shape)\n",
    "    print(y[0])\n",
    "    plt.imshow(np.array(X[0,0,:,:]));\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsTQ8j-WXJ-v"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mx5gNgwIXJ-y"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('conv1', nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1))\n",
    "model.add_module('batch1', nn.BatchNorm2d(16))\n",
    "model.add_module('relu1', nn.ReLU())  \n",
    "model.add_module('conv2', nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1))\n",
    "model.add_module('relu2', nn.ReLU())  \n",
    "model.add_module('batch2', nn.BatchNorm2d(16))\n",
    "model.add_module('max_pool1', nn.MaxPool2d(2, 2, padding=0))\n",
    "\n",
    "model.add_module('conv3', nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1))\n",
    "model.add_module('batch3', nn.BatchNorm2d(32))\n",
    "model.add_module('relu3', nn.ReLU()) \n",
    "model.add_module('conv4', nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1))\n",
    "model.add_module('batch4', nn.BatchNorm2d(32))\n",
    "model.add_module('relu4', nn.ReLU()) \n",
    "model.add_module('max_pool2', nn.MaxPool2d(2, 2, padding=0))\n",
    "\n",
    "model.add_module('conv5', nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1))\n",
    "model.add_module('batch5', nn.BatchNorm2d(64))\n",
    "model.add_module('relu5', nn.ReLU()) \n",
    "model.add_module('conv6', nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1))\n",
    "model.add_module('batch6', nn.BatchNorm2d(64))\n",
    "model.add_module('relu6', nn.ReLU()) \n",
    "model.add_module('max_pool3', nn.MaxPool2d(2, 2, padding=0))\n",
    "\n",
    "\n",
    "model.add_module('conv7', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1))\n",
    "model.add_module('batch7', nn.BatchNorm2d(128))\n",
    "model.add_module('relu7', nn.ReLU())  \n",
    "model.add_module('conv8', nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1))\n",
    "model.add_module('batch8', nn.BatchNorm2d(128))\n",
    "model.add_module('relu8', nn.ReLU())\n",
    "model.add_module('max_pool4', nn.MaxPool2d(2, 2, padding=0))\n",
    "\n",
    "model.add_module('flatten', Flatten())\n",
    "\n",
    "model.add_module('dense1', nn.Linear(2048, 1024, bias=False))  # 512*2*2\n",
    "model.add_module('relu13', nn.ReLU())\n",
    "model.add_module('dropout1', nn.Dropout(0.5))\n",
    "model.add_module('dense2', nn.Linear(1024, 200, bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucQOt2PdXJ-0"
   },
   "outputs": [],
   "source": [
    "def compute_loss(X_batch, y_batch):\n",
    "    X_batch = Variable(torch.FloatTensor(X_batch))\n",
    "    y_batch = Variable(torch.LongTensor(y_batch))\n",
    "    logits = model(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3020
    },
    "colab_type": "code",
    "id": "ICP0rS95XJ-3",
    "outputId": "74aeb0e5-5b41-4009-971d-b673f5ed7a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 35 took 1224.510s\n",
      "  training loss (in-iteration): \t5.001499\n",
      "  validation accuracy: \t\t\t7.25 %\n",
      "Epoch 2 of 35 took 1242.262s\n",
      "  training loss (in-iteration): \t4.470270\n",
      "  validation accuracy: \t\t\t12.27 %\n",
      "Epoch 3 of 35 took 1242.804s\n",
      "  training loss (in-iteration): \t4.199828\n",
      "  validation accuracy: \t\t\t14.81 %\n",
      "Epoch 4 of 35 took 1261.179s\n",
      "  training loss (in-iteration): \t4.015407\n",
      "  validation accuracy: \t\t\t17.19 %\n",
      "Epoch 5 of 35 took 1255.879s\n",
      "  training loss (in-iteration): \t3.883311\n",
      "  validation accuracy: \t\t\t18.66 %\n",
      "Epoch 6 of 35 took 1253.844s\n",
      "  training loss (in-iteration): \t3.778530\n",
      "  validation accuracy: \t\t\t19.26 %\n",
      "Epoch 7 of 35 took 1258.097s\n",
      "  training loss (in-iteration): \t3.690774\n",
      "  validation accuracy: \t\t\t20.77 %\n",
      "Epoch 8 of 35 took 1246.028s\n",
      "  training loss (in-iteration): \t3.614235\n",
      "  validation accuracy: \t\t\t21.83 %\n",
      "Epoch 9 of 35 took 1248.769s\n",
      "  training loss (in-iteration): \t3.540544\n",
      "  validation accuracy: \t\t\t23.25 %\n",
      "Epoch 10 of 35 took 1240.212s\n",
      "  training loss (in-iteration): \t3.473304\n",
      "  validation accuracy: \t\t\t24.36 %\n",
      "Epoch 11 of 35 took 1246.099s\n",
      "  training loss (in-iteration): \t3.417722\n",
      "  validation accuracy: \t\t\t25.38 %\n",
      "Epoch 12 of 35 took 1249.176s\n",
      "  training loss (in-iteration): \t3.370407\n",
      "  validation accuracy: \t\t\t26.26 %\n",
      "Epoch 13 of 35 took 1269.585s\n",
      "  training loss (in-iteration): \t3.325366\n",
      "  validation accuracy: \t\t\t26.53 %\n",
      "Epoch 14 of 35 took 1256.821s\n",
      "  training loss (in-iteration): \t3.276867\n",
      "  validation accuracy: \t\t\t27.30 %\n",
      "Epoch 15 of 35 took 1260.629s\n",
      "  training loss (in-iteration): \t3.241547\n",
      "  validation accuracy: \t\t\t27.68 %\n",
      "Epoch 16 of 35 took 1255.073s\n",
      "  training loss (in-iteration): \t3.198670\n",
      "  validation accuracy: \t\t\t28.16 %\n",
      "Epoch 17 of 35 took 1265.586s\n",
      "  training loss (in-iteration): \t3.159768\n",
      "  validation accuracy: \t\t\t28.50 %\n",
      "Epoch 18 of 35 took 1248.013s\n",
      "  training loss (in-iteration): \t3.125713\n",
      "  validation accuracy: \t\t\t29.47 %\n",
      "Epoch 19 of 35 took 1244.749s\n",
      "  training loss (in-iteration): \t3.095652\n",
      "  validation accuracy: \t\t\t30.10 %\n",
      "Epoch 20 of 35 took 1249.753s\n",
      "  training loss (in-iteration): \t3.064213\n",
      "  validation accuracy: \t\t\t30.65 %\n",
      "Epoch 21 of 35 took 1255.053s\n",
      "  training loss (in-iteration): \t3.034382\n",
      "  validation accuracy: \t\t\t30.47 %\n",
      "Epoch 22 of 35 took 1249.338s\n",
      "  training loss (in-iteration): \t3.010577\n",
      "  validation accuracy: \t\t\t30.57 %\n",
      "Epoch 23 of 35 took 1255.324s\n",
      "  training loss (in-iteration): \t2.977489\n",
      "  validation accuracy: \t\t\t30.91 %\n",
      "Epoch 24 of 35 took 1251.120s\n",
      "  training loss (in-iteration): \t2.952381\n",
      "  validation accuracy: \t\t\t31.39 %\n",
      "Epoch 25 of 35 took 1293.647s\n",
      "  training loss (in-iteration): \t2.924904\n",
      "  validation accuracy: \t\t\t32.08 %\n",
      "Epoch 26 of 35 took 1280.978s\n",
      "  training loss (in-iteration): \t2.907598\n",
      "  validation accuracy: \t\t\t32.22 %\n",
      "Epoch 27 of 35 took 1275.033s\n",
      "  training loss (in-iteration): \t2.876540\n",
      "  validation accuracy: \t\t\t32.19 %\n",
      "Epoch 28 of 35 took 1262.148s\n",
      "  training loss (in-iteration): \t2.864259\n",
      "  validation accuracy: \t\t\t32.46 %\n",
      "Epoch 29 of 35 took 1254.253s\n",
      "  training loss (in-iteration): \t2.839456\n",
      "  validation accuracy: \t\t\t33.26 %\n",
      "Epoch 30 of 35 took 1252.514s\n",
      "  training loss (in-iteration): \t2.817667\n",
      "  validation accuracy: \t\t\t33.59 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e7c2994e78f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# train on batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []\n",
    "\n",
    "num_epochs = 35 # total amount of full passes over training data\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train(True) # enable dropout / batch_norm training behavior\n",
    "    for (X_batch, y_batch) in train_batch_gen:\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "\n",
    "    \n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in val_batch_gen:\n",
    "        logits = model(Variable(torch.FloatTensor(X_batch)))\n",
    "        y_pred = logits.max(1)[1].data\n",
    "        val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
    "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "        np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STTozCLWHMkQ"
   },
   "source": [
    "Stopped the model due to the Collab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAdcOoIFy1MD"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YveWXfIx-ttq"
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load('Checkpoint.pth')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "myhqVa2YDvX2",
    "outputId": "7aafafb4-e344-4b3d-9afb-d85f1aa7e45f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 15 took 1212.931s\n",
      "  training loss (in-iteration): \t2.872272\n",
      "  validation accuracy: \t\t\t37.71 %\n",
      "Epoch 2 of 15 took 1220.260s\n",
      "  training loss (in-iteration): \t2.843887\n",
      "  validation accuracy: \t\t\t38.00 %\n",
      "Epoch 3 of 15 took 1259.606s\n",
      "  training loss (in-iteration): \t2.810568\n",
      "  validation accuracy: \t\t\t37.43 %\n",
      "Epoch 4 of 15 took 1257.793s\n",
      "  training loss (in-iteration): \t2.787693\n",
      "  validation accuracy: \t\t\t37.94 %\n",
      "Epoch 5 of 15 took 1259.672s\n",
      "  training loss (in-iteration): \t2.766222\n",
      "  validation accuracy: \t\t\t37.47 %\n",
      "Epoch 6 of 15 took 1257.370s\n",
      "  training loss (in-iteration): \t2.751547\n",
      "  validation accuracy: \t\t\t37.23 %\n",
      "Epoch 7 of 15 took 1237.180s\n",
      "  training loss (in-iteration): \t2.732216\n",
      "  validation accuracy: \t\t\t37.84 %\n",
      "Epoch 8 of 15 took 1205.719s\n",
      "  training loss (in-iteration): \t2.700253\n",
      "  validation accuracy: \t\t\t37.61 %\n",
      "Epoch 9 of 15 took 1218.860s\n",
      "  training loss (in-iteration): \t2.697625\n",
      "  validation accuracy: \t\t\t37.44 %\n",
      "Epoch 10 of 15 took 1199.664s\n",
      "  training loss (in-iteration): \t2.683227\n",
      "  validation accuracy: \t\t\t37.81 %\n",
      "Epoch 11 of 15 took 1202.079s\n",
      "  training loss (in-iteration): \t2.662674\n",
      "  validation accuracy: \t\t\t37.76 %\n",
      "Epoch 12 of 15 took 1200.394s\n",
      "  training loss (in-iteration): \t2.646498\n",
      "  validation accuracy: \t\t\t38.09 %\n",
      "Epoch 13 of 15 took 1203.694s\n",
      "  training loss (in-iteration): \t2.629942\n",
      "  validation accuracy: \t\t\t38.21 %\n",
      "Epoch 14 of 15 took 1205.386s\n",
      "  training loss (in-iteration): \t2.622753\n",
      "  validation accuracy: \t\t\t38.42 %\n",
      "Epoch 15 of 15 took 1205.116s\n",
      "  training loss (in-iteration): \t2.602746\n",
      "  validation accuracy: \t\t\t38.46 %\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []\n",
    "\n",
    "num_epochs = 15 # total amount of full passes over training data\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train(True) # enable dropout / batch_norm training behavior\n",
    "    for (X_batch, y_batch) in train_batch_gen:\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "\n",
    "    \n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in val_batch_gen:\n",
    "        logits = model(Variable(torch.FloatTensor(X_batch)))\n",
    "        y_pred = logits.max(1)[1].data\n",
    "        val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
    "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "        np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SH_WP-sGGav"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'CheckpointFinal.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJV79hclrBuA"
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load('CheckpointFinal.pth')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MklmN6SSXJ-6"
   },
   "source": [
    "When everything is done, please compute accuracy on the validation set and report it below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KxktjpC1XJ-9"
   },
   "source": [
    "# Report\n",
    "\n",
    "Below, please mention\n",
    "\n",
    "* a brief history of tweaks and improvements;\n",
    "* what is the final architecture and why?\n",
    "* what is the training method (batch size, optimization algorithm, ...) and why?\n",
    "* Any regularization and other techniques applied and their effects;\n",
    "\n",
    "The reference format is:\n",
    "\n",
    "*\"I have analyzed these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFT_bjzCXJ-9"
   },
   "source": [
    "Part 1.\n",
    "\n",
    "At the beginning, I simply applied the model from the seminar week 2 and run until 10 iterations. It did not include any convolutional layers. The obtained val score was 9.42% at 10 epoch, which obviously was not satisfactory, yet trained relatively fast as compared to subsequent models (~200 s/epoch).\n",
    "\n",
    "On the second trial, I applied 2 convolutional layers and max pool while not changing anything from the seminar's model. After epoch 10, val accuracy could not get higher than 16.77%.\n",
    "\n",
    "On the third trial, I applied data augmentation by adding normalization. The result did not change significantly.\n",
    "\n",
    "Then, I applied one more layer, where each convolution increases output relative to input channels. Thus, the last convolution had 128 output channels, and after each convolution there was a batch normalization and then ELU. The obtained val score could reach 21% at 10th epoch, however each iteration took 900 s/epoch on Collab with GPU option turned on.\n",
    "\n",
    "On the fith trial, architecture which distantly resembles VGGNet was created with 12 convolutional layers, which took a lot of time to train (~ 12 hours). The highest val score was 29.83% at epoch 8. However, the score did not improve and I stopped training the model at 32st epoch due to overfitting.\n",
    "\n",
    "To cope with long training time and overfitting, I applied more image transformations and reduced output channels for convolutional layers for the next trial. One important change was a switch from SGD optimizer to Adam optimizer. Particularly, the next models had 8 convolutional layers, image transofmations included random rotations, flips, and grayscale. As the result, the val score was lower than the previous model, yet no overfitting was registered. To explain the validation accuracy reduction, the precious model was more architecturally complex than the subsequent trials. For example, the first epoch for the \"fith\" model was 16%, while subsequent ones had around 6%. In addition, I converted images to grayscale, and it reduced computational time while increased validation error.\n",
    "\n",
    "Finally, this update contains a final model with a bunch of image transformations, tweaked 8 convolutional layers, and it could achieve 38%.\n",
    "\n",
    "Part 2 (UPD).\n",
    "\n",
    "The final model (as it here) was based on VGGNet because of uniform architecture and becuase of its easiness of applicability. Also, I analyzed an article on Medium by Siddharth Das, where he compares all known CNN architectures. According to the article, VGGNet is good at extracting features from images and serves as a baseline extracting patterns, which is a relevant task for the assignment. I also analyzed a VGGNet architecture from Pytorch Forum by shaqdc1, and I did it in a similar way.\n",
    "\n",
    "Looking into the model, it has a total 8 convolutional layers. One \"block\" starts with the first conv. layer with input channel less than output channel, and after such every conv. layer there are batch normalization and activation function. The next convolutional layers have the same input and output channels to widen the convolution block. The last part of the block is a maxpool layer.\n",
    "\n",
    "Part 3  & 4 ( UPD). \n",
    "\n",
    "I kept batch size of 50 as from the seminar since it occured to be optimal for my model based on subsequent trials. Speaking about activations, I kept ReLU as default since no significant impact on accuracy were shown by other types of activations. For the final model, I changed SGD optimization to Adam becuase of its known good performance. Also, I added normalization, random vertica and horizontal flips, rotations for transforming images, which helped my model to ovoid overfitting.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqIEWy0iXJ--"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework_part2_Anton_Morozov_Updated.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
